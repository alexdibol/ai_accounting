{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNdCRXVJP/w5HdwvuCRYUc6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI ACCOUNTING CHAPTER 2: REASONERS**\n","\n","---"],"metadata":{"id":"cnQK8yTVMAhC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"tw2-7uYoMGHg"}},{"cell_type":"markdown","source":["https://claude.ai/share/01696c05-ee2f-4a51-9765-836a503cc0fb"],"metadata":{"id":"axSMA0YpNnYX"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"4LFo5LtiMIff"}},{"cell_type":"markdown","source":["**Introduction: Building Trustworthy AI Systems for Professional Accounting and Audit**\n","\n","**Why This Notebook Matters**\n","\n","If you've used ChatGPT, Claude, or other AI chatbots for work, you've likely experienced both their remarkable capabilities and their concerning limitations. Perhaps you asked an AI to help draft a client memo and it sounded authoritative but cited nonexistent accounting standards. Maybe you used it to analyze financial data and couldn't explain to your supervisor exactly what assumptions the AI made. Or you simply felt uneasy about how easily these tools generate professional-sounding content without any documentation trail that would survive a quality control review.\n","\n","This notebook addresses a critical gap between casual AI experimentation and professional-grade AI deployment. While consumer chatbots are designed for convenience and general helpfulness, professional servicesâ€”especially accounting, auditing, and tax workâ€”demand something fundamentally different: auditability, reproducibility, and explicit risk management. The stakes are simply too high to treat AI as a magical black box that produces outputs we hope are correct.\n","\n","**The Professional Services Dilemma**\n","\n","Accounting and audit professionals face unique constraints that casual AI users don't encounter. When you sign off on financial statements, tax returns, or internal control assessments, you're accepting legal and ethical responsibility for that work. Regulators, courts, and professional standards bodies expect you to document your procedures, demonstrate professional skepticism, and maintain audit trails that could be scrutinized years later. None of the popular consumer AI chatbots were designed with these requirements in mind.\n","\n","Consider what happens in a typical ChatGPT conversation about a technical accounting issue. You describe a scenario, the AI provides an analysis citing ASC standards and offering conclusions about proper treatment. The response sounds confident and well-reasoned. But can you verify those citations are real? Can you reproduce the exact same analysis six months from now? Can you show a reviewer what facts you provided versus what the AI assumed? Can you demonstrate that you exercised professional skepticism by considering alternative interpretations? The answer to all these questions is usually no.\n","\n","This creates a dangerous paradox: AI tools are powerful enough to meaningfully assist professional work, but not trustworthy enough to rely upon without extensive safeguards. The solution isn't to ban AI from professional practiceâ€”that ship has sailed, and the productivity gains are too substantial to ignore. Instead, we need to engineer AI systems that respect the governance requirements of professional services from the ground up.\n","\n","**What This Notebook Teaches: Level 2 Reasoning with Full Governance**\n","\n","This notebook introduces you to \"Level 2 Reasoners\"â€”a specific approach to AI assistance that provides structured reasoning support while maintaining strict boundaries about what the AI can and cannot do. Unlike Level 1 systems (simple question-answering) or Level 3 systems (autonomous agents that execute multi-step tasks), Level 2 focuses on helping you structure your thinking without replacing your professional judgment.\n","\n","The architecture implements seven interconnected governance mechanisms that transform casual AI chat into auditable professional assistance:\n","\n","**Strict Input/Output Contracts:** Every AI interaction uses a mandatory JSON schema with eight required fieldsâ€”task description, facts provided, assumptions made, open questions, reasoning analysis, risk flags, draft output, and verification status. This structure forces both you and the AI to be explicit about what's known versus inferred versus missing.\n","\n","**Facts Versus Assumptions Discipline:** The system distinguishes rigorously between facts you explicitly stated and assumptions the AI inferred. This seemingly simple distinction is transformativeâ€”it prevents the common failure mode where AI confidently fills knowledge gaps with plausible-sounding fabrications, and you don't realize where your facts ended and the AI's guesswork began.\n","\n","**Confidentiality Protection:** Before any text reaches the AI, automated redaction utilities scan for personally identifiable informationâ€”emails, phone numbers, SSNs, addresses. While not perfect, this creates a safety net against accidental disclosure of client data. The system also implements data minimization principles, sending only the facts necessary for the reasoning task rather than entire documents.\n","\n","**\"Not Verified\" Discipline:** Whenever the AI references authoritative sources (ASC standards, PCAOB requirements, IRS regulations), the output is automatically flagged \"Not verified\" and includes a checklist of specific items to verify in the actual source materials. This prevents the dangerous practice of treating AI citations as reliable without independent confirmation.\n","\n","**Professional Skepticism by Design:** The system requires every analysis to include \"disconfirming evidence questions\"â€”specific inquiries that would challenge or falsify the working hypotheses. This operationalizes the professional skepticism standard that auditing standards require but that many practitioners struggle to apply consistently.\n","\n","**Complete Audit Trail:** Every run generates five artifact categoriesâ€”a run manifest with configuration details and cryptographic hashes, a prompts log with redacted interactions, a risk register documenting flagged issues, structured deliverables with human-readable summaries, and a final zip bundle containing the complete audit trail. Six months later, you can prove exactly what you asked, what the AI said, what risks were identified, and what configuration was used.\n","\n","**Automated Risk Flagging:** The system doesn't trust the AI to police itself. After each response, automated checks scan for missing open questions (suggesting overconfidence), unauthorized authority citations (suggesting hallucination), and conclusion-like language in sections that should contain reasoning notes only (suggesting boundary violations). Risks are categorized by type and severity, creating a structured register rather than vague unease.\n","\n","**The Notebook Structure: Ten Cells from Theory to Practice**\n","\n","The notebook follows a carefully designed progression across ten cells. Cell 1 orients you to the governance-first philosophy and explains what Level 2 reasoning means in plain English. Cells 2-3 handle the technical setupâ€”installing libraries, connecting to Claude's API, and configuring the model parameters that control response behavior.\n","\n","Cells 4-5 build the governance infrastructureâ€”the logging utilities, cryptographic hashing functions, redaction tools, and data minimization helpers that run invisibly in the background to ensure every interaction is documented and protected. Cell 6 implements the core \"reasoner wrapper\" that enforces the strict JSON schema, adds automated risk checks, and maintains the audit trail.\n","\n","Cell 7 defines four realistic mini-cases spanning financial statement audit, SOX/ICFR compliance, tax research, and training methodology. These aren't toy examplesâ€”they're modeled on actual professional scenarios with incomplete information, ambiguous facts, and judgment calls required. Cell 8 runs all four demos, generating structured outputs and a summary comparison table. Cell 9 turns the notebook interactive, letting you input your own scenario and receive the same governed reasoning support. Cell 10 packages everything into a downloadable audit trail with a comprehensive README explaining how to review and reproduce the work.\n","\n","**Key Lessons: What You Must Take Away**\n","\n","First, AI capability and AI risk scale togetherâ€”more powerful models require stronger controls, not weaker ones. The governance mechanisms in this notebook aren't obstacles to productivity; they're what make professional AI use possible at all.\n","\n","Second, the distinction between facts and assumptions is foundational to trustworthy AI assistance. Every time you interact with AI, ask yourself: what did I explicitly state, what did the AI infer, and what remains uncertain? If you can't answer clearly, you're not in control of the process.\n","\n","Third, verification is non-negotiable. \"Not verified\" isn't a bug or a limitationâ€”it's an accurate description of AI's relationship to authoritative sources. The AI can help you frame research questions and structure your analysis, but you must verify every citation, standard, or requirement yourself.\n","\n","Fourth, reproducibility requires deliberate engineering. The configuration hash, environment fingerprint, and cryptographic hashes aren't academic exercisesâ€”they're what separate casual experimentation from professional work product that could be defended in litigation or regulatory examination.\n","\n","Fifth, professional skepticism must be operationalized, not just preached. The requirement to generate disconfirming evidence questions transforms skepticism from an aspirational standard into a concrete deliverable that reviewers can evaluate.\n","\n","Finally, AI is not a substitute for professional judgmentâ€”it's a tool for structuring that judgment more systematically. The goal isn't to let AI make decisions for you; it's to make your own decision-making process more rigorous, transparent, and defensible.\n","\n","This notebook represents one possible answer to the question: how do we harness AI's analytical power while respecting the governance requirements of professional services? The specific implementation details will evolve as models improve and standards develop, but the underlying principlesâ€”explicit boundaries, rigorous documentation, facts versus assumptions, verification discipline, and audit trailsâ€”will remain essential to any trustworthy professional AI system."],"metadata":{"id":"6n-x0MLbMKUs"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"HzSSYRQ0MKs8"}},{"cell_type":"code","source":["# Cell 2: Install Dependencies + Imports + Run Directory Setup\n","\n","print(\"=\" * 70)\n","print(\"CELL 2: Installing dependencies and setting up run environment\")\n","print(\"=\" * 70)\n","\n","# Install anthropic library\n","!pip install -q anthropic\n","\n","# Standard library imports\n","import json\n","import os\n","import re\n","import hashlib\n","import platform\n","import textwrap\n","from datetime import datetime\n","from pathlib import Path\n","import subprocess\n","\n","print(\"\\nâœ“ Dependencies installed\")\n","print(\"âœ“ Imports loaded: json, os, re, hashlib, platform, datetime, pathlib, subprocess\")\n","\n","# Create run directory with timestamp\n","timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","RUN_BASE_DIR = Path(\"/content/ai_audit_ch2_runs\")\n","RUN_DIR = RUN_BASE_DIR / f\"run_{timestamp_str}\"\n","DELIVERABLES_DIR = RUN_DIR / \"deliverables\"\n","\n","# Create directories\n","RUN_DIR.mkdir(parents=True, exist_ok=True)\n","DELIVERABLES_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(f\"\\nâœ“ Run directory created: {RUN_DIR}\")\n","print(f\"âœ“ Deliverables directory: {DELIVERABLES_DIR}\")\n","print(\"\\nReady to proceed to API key setup (Cell 3)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPm_4UyighKz","executionInfo":{"status":"ok","timestamp":1768159367912,"user_tz":360,"elapsed":12886,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"54b4b4fb-b36a-4982-8ad7-e0bc99fb5a4d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 2: Installing dependencies and setting up run environment\n","======================================================================\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\n","âœ“ Dependencies installed\n","âœ“ Imports loaded: json, os, re, hashlib, platform, datetime, pathlib, subprocess\n","\n","âœ“ Run directory created: /content/ai_audit_ch2_runs/run_20260111_192247\n","âœ“ Deliverables directory: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables\n","\n","Ready to proceed to API key setup (Cell 3)\n"]}]},{"cell_type":"markdown","source":["##3.API CALL AND CLAUDE CLIENT INITIALIZATION"],"metadata":{"id":"STtjBQgwMNHi"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ShWjt_vyMO17"}},{"cell_type":"markdown","source":["**Cell 3: Setting Up Your Connection to Claude**\n","\n","**What This Cell Does:**\n","\n","This cell establishes the vital connection between your Google Colab notebook and Anthropic's Claude AI system. Think of it as plugging in a power cord before you can use an applianceâ€”without this connection, none of the AI reasoning capabilities will work.\n","\n","**Why API Keys Matter:**\n","\n","An API key is like a secure password that allows your notebook to communicate with Claude's servers. Anthropic provides these keys to verified users, and they come with usage limits and security protections. You store this key in Colab's \"Secrets\" feature (found in the left sidebar with a key icon ðŸ”‘), which keeps it encrypted and hidden from anyone who might view your notebook later.\n","\n","**The Three Critical Settings:**\n","\n","Once the key is loaded, this cell configures three technical parameters that control how Claude responds:\n","\n","**Model Selection:** We use \"claude-sonnet-4-5-20250929,\" which is Anthropic's most advanced reasoning model as of this training program. Different models have different strengthsâ€”this one excels at structured analytical thinking, which is exactly what CPAs and auditors need.\n","\n","**Temperature (0.2):** This setting controls randomness in Claude's responses. Temperature ranges from 0 to 1, where 0 means completely deterministic (same input always produces same output) and 1 means highly creative and varied. We set it to 0.2 because accounting and audit work demands consistency and reliability. You want Claude to structure your thinking the same way each time, not give you wildly different hypotheses for the same set of facts.\n","\n","**Max Tokens (1,200):** A \"token\" is roughly equivalent to a word or word fragment. By limiting responses to 1,200 tokens, we ensure Claude provides focused, actionable outputs rather than lengthy essays. This keeps the reasoning support practical and forces the model to prioritize the most important insights.\n","\n","**What Success Looks Like:**\n","\n","When this cell runs successfully, you'll see confirmation messages showing that your API key loaded correctly and displaying your model configuration. If something goes wrong, the cell provides clear instructions on how to add your API key to Colab's secrets. Without this setup, the rest of the notebook cannot function, so take time to get this right before proceeding."],"metadata":{"id":"n_uMwdv8MRcU"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Xml9f9GoMR7J"}},{"cell_type":"code","source":["# Cell 3: API Key + Client Initialization\n","\n","print(\"=\" * 70)\n","print(\"CELL 3: API Key and Anthropic Client Initialization\")\n","print(\"=\" * 70)\n","\n","import anthropic\n","from google.colab import userdata\n","\n","# Retrieve API key from Colab secrets\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","    api_key_loaded = True\n","    print(\"\\nâœ“ API key loaded: YES\")\n","except Exception as e:\n","    api_key_loaded = False\n","    print(f\"\\nâœ— API key loaded: NO\")\n","    print(f\"Error: {e}\")\n","    print(\"\\nTo fix: Go to Colab menu â†’ Secrets (ðŸ”‘) â†’ Add 'ANTHROPIC_API_KEY'\")\n","\n","if api_key_loaded:\n","    # Initialize Anthropic client\n","    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","\n","    # Model configuration - HIGH token limit for detailed accounting scenarios\n","    MODEL = \"claude-sonnet-4-5-20250929\"\n","    TEMPERATURE = 0.2\n","    MAX_TOKENS = 8000  # Increased to 8000 for complex multi-section outputs\n","\n","    print(f\"\\nâœ“ Anthropic client initialized\")\n","    print(f\"âœ“ Model: {MODEL}\")\n","    print(f\"âœ“ Temperature: {TEMPERATURE} (low for deterministic reasoning)\")\n","    print(f\"âœ“ Max tokens: {MAX_TOKENS} (high limit for detailed analysis)\")\n","    print(\"\\nReady to proceed to governance utilities (Cell 4)\")\n","else:\n","    print(\"\\nâš  Cannot proceed without API key. Please add it to Colab secrets.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRs_DQYSnYYQ","executionInfo":{"status":"ok","timestamp":1768161120783,"user_tz":360,"elapsed":589,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"00198220-b18d-4ec9-d4d2-2a870f5122b7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 3: API Key and Anthropic Client Initialization\n","======================================================================\n","\n","âœ“ API key loaded: YES\n","\n","âœ“ Anthropic client initialized\n","âœ“ Model: claude-sonnet-4-5-20250929\n","âœ“ Temperature: 0.2 (low for deterministic reasoning)\n","âœ“ Max tokens: 8000 (high limit for detailed analysis)\n","\n","Ready to proceed to governance utilities (Cell 4)\n"]}]},{"cell_type":"markdown","source":["##4.GOVERNANCE UTILITIES"],"metadata":{"id":"zSjFjeDuMaZn"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"6OWXlpZoMcHa"}},{"cell_type":"markdown","source":["**Cell 4: Building the Governance Foundation â€“ Your Audit Trail Begins Here**\n","\n","**What This Cell Does:**\n","\n","This cell creates the complete infrastructure for tracking and documenting every action the AI takes during your session. Think of it as setting up a flight recorder in an airplaneâ€”it captures everything that happens so you can review, audit, and reproduce the work later. In professional accounting and audit contexts, this kind of documentation isn't optional; it's essential for quality control and regulatory compliance.\n","\n","**The Five Critical Utility Functions:**\n","\n","This cell defines five helper functions that will be used throughout the notebook. The **now_iso()** function captures precise timestamps in international standard format, ensuring you know exactly when each AI interaction occurred. The **sha256_text()** function creates unique digital fingerprints (called cryptographic hashes) of every prompt and responseâ€”these fingerprints prove that content hasn't been altered and allow you to trace outputs back to their sources.\n","\n","The **write_json()** and **append_jsonl()** functions handle saving structured data to files. JSON is a universal format that both humans and computers can read easily. Finally, **get_env_fingerprint()** captures technical details about your computing environmentâ€”Python version, operating system, library versionsâ€”so someone else could theoretically recreate your exact setup months or years later.\n","\n","**The Configuration Hash:**\n","\n","One of the most important innovations here is the configuration hash. The cell takes all your settings (which model you're using, what temperature, what controls are active) and creates a unique identifier. If you run this notebook tomorrow with identical settings, you'll get the same hash. If anything changesâ€”even slightlyâ€”the hash changes. This is crucial for reproducibility in professional work.\n","\n","**The Three Governance Files:**\n","\n","The cell immediately creates three files in your run directory. The **run_manifest.json** serves as your master recordâ€”it contains your run ID, timestamp, all configuration settings, and environment details. The **prompts_log.jsonl** starts as an empty file that will capture every interaction with Claude (we'll add to it later). The **risk_log.json** begins as an empty risk register that will track potential issues as they're identified.\n","\n","These aren't just bureaucratic requirementsâ€”they're your evidence that you exercised appropriate professional skepticism and maintained proper documentation standards."],"metadata":{"id":"XdRc9-nEMeIF"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"GvnsRIc6Mefx"}},{"cell_type":"code","source":["# Cell 4: Governance â€” Manifest + Logging Utilities\n","\n","print(\"=\" * 70)\n","print(\"CELL 4: Governance Utilities and Run Manifest\")\n","print(\"=\" * 70)\n","\n","def now_iso():\n","    \"\"\"Return current UTC timestamp in ISO format\"\"\"\n","    from datetime import datetime, timezone\n","    return datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')\n","\n","def sha256_text(text):\n","    \"\"\"Compute SHA256 hash of text\"\"\"\n","    return hashlib.sha256(text.encode('utf-8')).hexdigest()\n","\n","def write_json(filepath, data):\n","    \"\"\"Write JSON data to file with pretty formatting\"\"\"\n","    with open(filepath, 'w', encoding='utf-8') as f:\n","        json.dump(data, f, indent=2, ensure_ascii=False)\n","\n","def append_jsonl(filepath, data):\n","    \"\"\"Append JSON object as single line to JSONL file\"\"\"\n","    with open(filepath, 'a', encoding='utf-8') as f:\n","        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n","\n","def get_env_fingerprint():\n","    \"\"\"Capture environment details for reproducibility\"\"\"\n","    try:\n","        python_version = platform.python_version()\n","        system_info = f\"{platform.system()} {platform.release()}\"\n","\n","        # Try to get anthropic library version\n","        try:\n","            import anthropic\n","            anthropic_version = anthropic.__version__\n","        except:\n","            anthropic_version = \"unknown\"\n","\n","        return {\n","            \"python_version\": python_version,\n","            \"system\": system_info,\n","            \"anthropic_version\": anthropic_version,\n","            \"platform\": platform.platform()\n","        }\n","    except Exception as e:\n","        return {\"error\": str(e)}\n","\n","print(\"âœ“ Utility functions defined:\")\n","print(\"  - now_iso(), sha256_text(), write_json(), append_jsonl(), get_env_fingerprint()\")\n","\n","# Define base configuration\n","BASE_CONFIG = {\n","    \"chapter\": 2,\n","    \"level\": 2,\n","    \"level_name\": \"Reasoners\",\n","    \"model\": MODEL,\n","    \"temperature\": TEMPERATURE,\n","    \"max_tokens\": MAX_TOKENS,\n","    \"controls\": [\n","        \"strict_json_schema\",\n","        \"confidentiality_redaction\",\n","        \"not_verified_discipline\",\n","        \"facts_vs_assumptions\",\n","        \"risk_flagging\",\n","        \"level_2_boundary_enforcement\"\n","    ]\n","}\n","\n","# Compute config hash\n","config_str = json.dumps(BASE_CONFIG, sort_keys=True)\n","config_hash = sha256_text(config_str)\n","config_hash_prefix = config_hash[:12]\n","\n","# Generate RUN_ID\n","RUN_ID = f\"{timestamp_str}_{config_hash_prefix}\"\n","\n","print(f\"\\nâœ“ Config hash computed: {config_hash_prefix}\")\n","print(f\"âœ“ RUN_ID: {RUN_ID}\")\n","\n","# Create run manifest\n","env_fingerprint = get_env_fingerprint()\n","run_manifest = {\n","    \"run_id\": RUN_ID,\n","    \"timestamp_utc\": now_iso(),\n","    \"chapter\": 2,\n","    \"level\": 2,\n","    \"model\": MODEL,\n","    \"parameters\": {\n","        \"temperature\": TEMPERATURE,\n","        \"max_tokens\": MAX_TOKENS\n","    },\n","    \"config_hash\": config_hash,\n","    \"config\": BASE_CONFIG,\n","    \"environment\": env_fingerprint,\n","    \"run_directory\": str(RUN_DIR)\n","}\n","\n","manifest_path = RUN_DIR / \"run_manifest.json\"\n","write_json(manifest_path, run_manifest)\n","print(f\"\\nâœ“ run_manifest.json created: {manifest_path}\")\n","\n","# Initialize prompts log (empty JSONL)\n","prompts_log_path = RUN_DIR / \"prompts_log.jsonl\"\n","prompts_log_path.touch()\n","print(f\"âœ“ prompts_log.jsonl initialized: {prompts_log_path}\")\n","\n","# Initialize risk log (empty register)\n","risk_log = {\n","    \"run_id\": RUN_ID,\n","    \"created_utc\": now_iso(),\n","    \"entries\": []\n","}\n","risk_log_path = RUN_DIR / \"risk_log.json\"\n","write_json(risk_log_path, risk_log)\n","print(f\"âœ“ risk_log.json initialized: {risk_log_path}\")\n","\n","print(\"\\nâœ“ Governance artifacts ready\")\n","print(\"Ready to proceed to confidentiality utilities (Cell 5)\")"],"metadata":{"id":"AY_6OY4SMbAv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768160932207,"user_tz":360,"elapsed":24,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"94484488-d980-4ad5-9c7a-f7232ee77374"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 4: Governance Utilities and Run Manifest\n","======================================================================\n","âœ“ Utility functions defined:\n","  - now_iso(), sha256_text(), write_json(), append_jsonl(), get_env_fingerprint()\n","\n","âœ“ Config hash computed: 22c12306caf0\n","âœ“ RUN_ID: 20260111_192247_22c12306caf0\n","\n","âœ“ run_manifest.json created: /content/ai_audit_ch2_runs/run_20260111_192247/run_manifest.json\n","âœ“ prompts_log.jsonl initialized: /content/ai_audit_ch2_runs/run_20260111_192247/prompts_log.jsonl\n","âœ“ risk_log.json initialized: /content/ai_audit_ch2_runs/run_20260111_192247/risk_log.json\n","\n","âœ“ Governance artifacts ready\n","Ready to proceed to confidentiality utilities (Cell 5)\n"]}]},{"cell_type":"markdown","source":["##5.CONFIDENTIALITY  UTILITIES"],"metadata":{"id":"aFfOfCZmMgx4"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"tIlOMU-SMjni"}},{"cell_type":"markdown","source":["**Cell 5: Protecting Confidentiality â€“ Redacting Sensitive Information**\n","\n","**What This Cell Does:**\n","\n","This cell creates your first line of defense against accidentally exposing confidential client information. Even though you should only use synthetic or redacted data in this training notebook, mistakes happen. This cell provides automated utilities that scan text for personally identifiable information (PII) and mask it before sending anything to Claude or saving it to your audit trail.\n","\n","**Understanding the Redaction Function:**\n","\n","The **redact()** function works like a smart search-and-replace tool. It uses pattern-matching techniques (called regular expressions) to identify common types of sensitive data: email addresses, phone numbers, Social Security numbers, and street addresses. When it finds these patterns, it replaces them with placeholders like [EMAIL_REDACTED] or [PHONE_REDACTED]. The function also attempts to identify potential names by looking for capitalized words appearing together, though this is less reliable and may flag false positives.\n","\n","**Why Redaction Isn't Perfect:**\n","\n","Here's a critical point that every professional must understand: automated redaction is helpful but not foolproof. The patterns this cell uses work well for standard formats (like 555-123-4567 for phone numbers or john@example.com for emails), but they can miss unusual formatting or context-specific sensitive information. For example, the function won't catch \"John's personal account number is ABC123\" because account numbers don't follow predictable patterns. This is why the cell includes prominent warnings reminding you never to paste real client data.\n","\n","**The Minimum-Necessary Principle:**\n","\n","The **build_minimum_necessary()** function implements a data minimization strategy borrowed from privacy regulations like GDPR and HIPAA. It takes your input text, runs it through redaction, and then formats it as a clean bullet-point list. It also generates a summary showing what types of information were removed. This serves two purposes: it makes the facts easier for Claude to process in structured format, and it gives you a clear record of what was sanitized.\n","\n","**The Demonstration:**\n","\n","The cell includes a live demonstration using synthetic data (a fake client scenario with email, phone, SSN, and address). You'll see the before-and-after comparison, which helps you understand exactly what the redaction function catches and what it might miss. This transparency is intentionalâ€”you need to know the limitations of your tools."],"metadata":{"id":"ksHvcArXMxMR"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"x7z8cMnQMx3g"}},{"cell_type":"code","source":["# Cell 5: Confidentiality Utilities â€” Redaction + Minimum-Necessary Facts Builder\n","\n","print(\"=\" * 70)\n","print(\"CELL 5: Confidentiality and Data Minimization Utilities\")\n","print(\"=\" * 70)\n","\n","def redact(text):\n","    \"\"\"\n","    Redact PII from text. Returns (redacted_text, removed_fields).\n","    WARNING: This is a heuristic-based redaction; not perfect. Use with caution.\n","    \"\"\"\n","    if not text:\n","        return text, []\n","\n","    redacted = text\n","    removed = []\n","\n","    # Email addresses\n","    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n","    if re.search(email_pattern, redacted):\n","        redacted = re.sub(email_pattern, '[EMAIL_REDACTED]', redacted)\n","        removed.append(\"email_addresses\")\n","\n","    # Phone numbers (various formats)\n","    phone_pattern = r'\\b(?:\\+?1[-.]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n","    if re.search(phone_pattern, redacted):\n","        redacted = re.sub(phone_pattern, '[PHONE_REDACTED]', redacted)\n","        removed.append(\"phone_numbers\")\n","\n","    # SSN (XXX-XX-XXXX)\n","    ssn_pattern = r'\\b\\d{3}-\\d{2}-\\d{4}\\b'\n","    if re.search(ssn_pattern, redacted):\n","        redacted = re.sub(ssn_pattern, '[SSN_REDACTED]', redacted)\n","        removed.append(\"ssn\")\n","\n","    # Street addresses (simplified heuristic)\n","    address_pattern = r'\\b\\d+\\s+[A-Z][a-z]+\\s+(?:Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct)\\.?\\b'\n","    if re.search(address_pattern, redacted):\n","        redacted = re.sub(address_pattern, '[ADDRESS_REDACTED]', redacted)\n","        removed.append(\"street_addresses\")\n","\n","    # Names heuristic (capitalized words >= 2, may have false positives)\n","    # Only flag, don't auto-redact (too many false positives)\n","    name_pattern = r'\\b[A-Z][a-z]+\\s+[A-Z][a-z]+\\b'\n","    if re.search(name_pattern, redacted):\n","        removed.append(\"possible_names_detected_not_redacted\")\n","\n","    return redacted, removed\n","\n","def build_minimum_necessary(text):\n","    \"\"\"\n","    Extract sanitized facts in bullet format, showing what was removed.\n","    Returns (sanitized_facts_bullets, removed_fields_summary)\n","    \"\"\"\n","    redacted_text, removed = redact(text)\n","\n","    # Convert to bullet list\n","    lines = redacted_text.strip().split('\\n')\n","    bullets = []\n","    for line in lines:\n","        line = line.strip()\n","        if line:\n","            if not line.startswith('â€¢'):\n","                bullets.append(f\"â€¢ {line}\")\n","            else:\n","                bullets.append(line)\n","\n","    sanitized_facts = '\\n'.join(bullets)\n","    removed_summary = ', '.join(removed) if removed else 'none'\n","\n","    return sanitized_facts, removed_summary\n","\n","print(\"âœ“ Redaction utilities defined: redact(), build_minimum_necessary()\")\n","\n","# Demo with synthetic data\n","print(\"\\n\" + \"=\"*70)\n","print(\"DEMO: Redaction in Action\")\n","print(\"=\"*70)\n","\n","demo_text = \"\"\"\n","Client: John Smith at ABC Corp (john.smith@abccorp.com, 555-123-4567)\n","Address: 123 Main Street, New York\n","SSN: 123-45-6789\n","Revenue for Q3 was $5M, up 15% YoY\n","Identified control deficiency in accounts payable process\n","\"\"\"\n","\n","print(\"\\nBEFORE REDACTION:\")\n","print(demo_text)\n","\n","redacted_demo, removed_fields = redact(demo_text)\n","\n","print(\"\\nAFTER REDACTION:\")\n","print(redacted_demo)\n","\n","print(f\"\\nREMOVED FIELDS: {', '.join(removed_fields) if removed_fields else 'none'}\")\n","\n","print(\"\\nâš  IMPORTANT: Redaction is heuristic-based and may miss PII.\")\n","print(\"   Always review outputs and use synthetic data when possible.\")\n","\n","print(\"\\nReady to proceed to LLM wrapper (Cell 6)\")"],"metadata":{"id":"_OdMQ8SwMiEp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768160936370,"user_tz":360,"elapsed":20,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"1e365df4-7d56-4beb-bea1-b349cd7ac9f5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 5: Confidentiality and Data Minimization Utilities\n","======================================================================\n","âœ“ Redaction utilities defined: redact(), build_minimum_necessary()\n","\n","======================================================================\n","DEMO: Redaction in Action\n","======================================================================\n","\n","BEFORE REDACTION:\n","\n","Client: John Smith at ABC Corp (john.smith@abccorp.com, 555-123-4567)\n","Address: 123 Main Street, New York\n","SSN: 123-45-6789\n","Revenue for Q3 was $5M, up 15% YoY\n","Identified control deficiency in accounts payable process\n","\n","\n","AFTER REDACTION:\n","\n","Client: John Smith at ABC Corp ([EMAIL_REDACTED], [PHONE_REDACTED])\n","Address: [ADDRESS_REDACTED], New York\n","SSN: [SSN_REDACTED]\n","Revenue for Q3 was $5M, up 15% YoY\n","Identified control deficiency in accounts payable process\n","\n","\n","REMOVED FIELDS: email_addresses, phone_numbers, ssn, street_addresses, possible_names_detected_not_redacted\n","\n","âš  IMPORTANT: Redaction is heuristic-based and may miss PII.\n","   Always review outputs and use synthetic data when possible.\n","\n","Ready to proceed to LLM wrapper (Cell 6)\n"]}]},{"cell_type":"markdown","source":["##6.CLAUDE WRAPPER"],"metadata":{"id":"uVJjvhvVM0E8"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"MyxD2F2XM1J3"}},{"cell_type":"markdown","source":["**Cell 6: The AI Wrapper â€“ Enforcing Disciplined Reasoning**\n","\n","**What This Cell Does:**\n","\n","This is arguably the most important cell in the entire notebook. It creates the **call_reasoner()** function, which serves as your controlled interface to Claude. Rather than sending raw questions to the AI and hoping for useful answers, this wrapper enforces strict rules about how Claude must respond, what format it must use, and what safety checks must pass before you see any output.\n","\n","**The System Prompt â€“ Your Instruction Manual for Claude:**\n","\n","Think of the system prompt as a detailed job description you're giving to an employee. It explicitly tells Claude what Level 2 reasoning means: structure thinking, identify gaps, generate hypotheses, but never claim to have performed procedures or verified evidence. The prompt enforces a mandatory JSON output format with eight required fields that must appear in exact order. This isn't arbitraryâ€”structured outputs are easier to audit, validate, and integrate into your workflow than free-form text.\n","\n","**Facts, Assumptions, and Open Questions:**\n","\n","The system prompt makes a critical distinction that many AI users overlook. The **facts_provided** field must contain only what you explicitly stated in your input. The **assumptions** field captures what Claude inferred or filled in mentallyâ€”these must be validated by you, the professional. The **open_questions** field is required because no scenario ever has complete information. By forcing Claude to articulate what's missing, you're building professional skepticism directly into the AI's output.\n","\n","**Automated Risk Flagging:**\n","\n","After Claude responds, the wrapper doesn't just accept the output blindly. It runs three automated quality checks. First, if Claude forgot to include open questions, the system flags a \"missing_facts\" riskâ€”suggesting the analysis might be overconfident. Second, if the response mentions authorities like ASC, PCAOB, or SEC without marking them \"Not verified,\" it flags a high-severity hallucination risk. Third, if the analysis uses conclusive language like \"therefore\" or \"must be,\" it flags an overreach risk, reminding you this is reasoning support, not a final conclusion.\n","\n","**The Audit Trail Connection:**\n","\n","Every call to this function automatically logs a redacted version of the prompt and response to your prompts_log.jsonl file, along with cryptographic hashes. It also updates the risk_log.json with any flagged issues. This happens transparently in the background, ensuring your audit trail stays complete without extra effort."],"metadata":{"id":"NbI8D2MMNp2V"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HYi01MJHM25b"}},{"cell_type":"code","source":["# Cell 6: LLM Wrapper â€” Level 2 Reasoner Call with Strict JSON + Risk Flags\n","\n","print(\"=\" * 70)\n","print(\"CELL 6: LLM Wrapper for Level 2 Reasoned Structuring\")\n","print(\"=\" * 70)\n","\n","# Define strict JSON schema enforcement\n","SYSTEM_PROMPT = \"\"\"You are a Level 2 Reasoner providing structured reasoning support for US CPAs and auditors.\n","\n","LEVEL 2 BOUNDARY (STRICT):\n","- You provide structured reasoning support ONLY\n","- You do NOT perform procedures, verify evidence, or provide final conclusions\n","- You do NOT act as an autonomous agent or orchestrator\n","- You structure thinking: hypotheses, issue lists, research scaffolds, disconfirming-evidence questions\n","\n","OUTPUT FORMAT (MANDATORY):\n","Return ONLY valid JSON with these keys in EXACT order. No markdown, no code blocks, no explanation - JUST the JSON object:\n","\n","{\n","  \"task\": \"brief task description\",\n","  \"facts_provided\": [\"fact 1\", \"fact 2\"],\n","  \"assumptions\": [\"assumption 1\", \"assumption 2\"],\n","  \"open_questions\": [\"question 1\", \"question 2\"],\n","  \"analysis\": \"reasoning structure notes (WHY these hypotheses/questions, NOT technical conclusions)\",\n","  \"risks\": [\n","    {\"type\": \"confidentiality|independence|hallucination|missing_facts|qc|prompt_injection|overreach|other\",\n","     \"severity\": \"low|medium|high\",\n","     \"note\": \"explanation\"}\n","  ],\n","  \"draft_output\": \"the structured deliverable with disclaimer\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"verification question 1\"]\n","}\n","\n","CRITICAL RULES:\n","1. facts_provided = only what was explicitly stated in input\n","2. assumptions = what you inferred (must be validated by user)\n","3. open_questions = REQUIRED; what's missing\n","4. analysis = reasoning notes, NOT conclusions\n","5. draft_output MUST begin with: \"NOT ACCOUNTING/AUDIT/TAX ADVICE. CPA review and engagement sign-off required.\"\n","6. If you reference ASC/PCAOB/AICPA/SEC, keep \"Not verified\" and populate questions_to_verify\n","7. Never claim procedures were performed or evidence exists unless stated in facts_provided\n","8. Be skeptical: always include disconfirming-evidence questions\n","\n","Return ONLY the raw JSON object. Do not wrap it in markdown code blocks. Do not add any text before or after the JSON.\"\"\"\n","\n","def clean_json_response(text):\n","    \"\"\"\n","    Clean potential markdown formatting from JSON response\n","    \"\"\"\n","    # Remove markdown code blocks if present\n","    text = text.strip()\n","\n","    # Remove ```json and ``` markers\n","    if text.startswith('```json'):\n","        text = text[7:]\n","    elif text.startswith('```'):\n","        text = text[3:]\n","\n","    if text.endswith('```'):\n","        text = text[:-3]\n","\n","    # Strip whitespace again\n","    text = text.strip()\n","\n","    return text\n","\n","def call_reasoner(task_name, user_prompt, facts_bullets):\n","    \"\"\"\n","    Call Claude with Level 2 system prompt, enforce strict JSON, add risk flags.\n","    Returns parsed JSON or None on failure.\n","    \"\"\"\n","    print(f\"\\n{'â”€'*70}\")\n","    print(f\"Calling reasoner: {task_name}\")\n","    print(f\"{'â”€'*70}\")\n","\n","    # Construct user message\n","    full_prompt = f\"\"\"TASK: {task_name}\n","\n","FACTS PROVIDED (minimum necessary):\n","{facts_bullets}\n","\n","{user_prompt}\n","\n","CRITICAL: Return ONLY the raw JSON object as specified in the system prompt. No markdown code blocks, no explanations, no preamble. Start your response with {{ and end with }}.\"\"\"\n","\n","    # Redact prompt for logging\n","    prompt_redacted, _ = redact(full_prompt)\n","    prompt_hash = sha256_text(full_prompt)\n","\n","    try:\n","        # Call Anthropic API\n","        response = client.messages.create(\n","            model=MODEL,\n","            max_tokens=MAX_TOKENS,\n","            temperature=TEMPERATURE,\n","            system=SYSTEM_PROMPT,\n","            messages=[{\"role\": \"user\", \"content\": full_prompt}]\n","        )\n","\n","        # Check if response was truncated\n","        if response.stop_reason == \"max_tokens\":\n","            print(f\"âš  WARNING: Response hit max_tokens limit ({MAX_TOKENS})\")\n","            print(f\"âš  Output may be incomplete. Consider increasing MAX_TOKENS in Cell 3.\")\n","            return None\n","\n","        response_text = response.content[0].text.strip()\n","\n","        # Clean any markdown formatting\n","        cleaned_response = clean_json_response(response_text)\n","\n","        # Redact response for logging\n","        response_redacted, _ = redact(cleaned_response)\n","        response_hash = sha256_text(cleaned_response)\n","\n","        # Log to prompts_log.jsonl\n","        log_entry = {\n","            \"timestamp_utc\": now_iso(),\n","            \"task_name\": task_name,\n","            \"prompt_redacted\": prompt_redacted[:500] + \"...\" if len(prompt_redacted) > 500 else prompt_redacted,\n","            \"prompt_hash\": prompt_hash,\n","            \"response_redacted\": response_redacted[:500] + \"...\" if len(response_redacted) > 500 else response_redacted,\n","            \"response_hash\": response_hash,\n","            \"model\": MODEL,\n","            \"temperature\": TEMPERATURE\n","        }\n","        append_jsonl(prompts_log_path, log_entry)\n","\n","        # Parse JSON\n","        try:\n","            result = json.loads(cleaned_response)\n","        except json.JSONDecodeError as e:\n","            print(f\"âš  JSON parse failed: {str(e)}\")\n","            print(f\"âš  First 200 chars of response: {cleaned_response[:200]}\")\n","\n","            # Retry once with explicit fix request\n","            print(\"âš  Attempting fix with explicit instruction...\")\n","            fix_prompt = f\"\"\"The following response should be valid JSON but has formatting issues.\n","Return ONLY the corrected JSON object with no markdown code blocks, no explanation, no preamble.\n","Start with {{ and end with }}.\n","\n","Response to fix:\n","{cleaned_response}\"\"\"\n","\n","            fix_response = client.messages.create(\n","                model=MODEL,\n","                max_tokens=MAX_TOKENS,\n","                temperature=0,\n","                messages=[{\"role\": \"user\", \"content\": fix_prompt}]\n","            )\n","\n","            fixed_text = fix_response.content[0].text.strip()\n","            fixed_text = clean_json_response(fixed_text)\n","\n","            result = json.loads(fixed_text)\n","            print(\"âœ“ JSON fixed and parsed\")\n","\n","        # Automated risk flags\n","        automated_risks = []\n","\n","        # Risk: missing open_questions\n","        if not result.get(\"open_questions\") or len(result.get(\"open_questions\", [])) == 0:\n","            automated_risks.append({\n","                \"type\": \"missing_facts\",\n","                \"severity\": \"medium\",\n","                \"note\": \"No open_questions provided; facts may be incomplete\"\n","            })\n","\n","        # Risk: authority-like tokens without verification\n","        authority_tokens = [\"ASC\", \"PCAOB\", \"AICPA\", \"SEC\", \"GAAS\", \"FASB\"]\n","        response_upper = cleaned_response.upper()\n","        found_authorities = [tok for tok in authority_tokens if tok in response_upper]\n","\n","        if found_authorities and result.get(\"verification_status\") != \"Not verified\":\n","            automated_risks.append({\n","                \"type\": \"hallucination\",\n","                \"severity\": \"high\",\n","                \"note\": f\"Authority-like tokens detected ({', '.join(found_authorities)}) but verification_status not set to 'Not verified'\"\n","            })\n","\n","        if found_authorities and (not result.get(\"questions_to_verify\") or len(result.get(\"questions_to_verify\", [])) == 0):\n","            automated_risks.append({\n","                \"type\": \"hallucination\",\n","                \"severity\": \"high\",\n","                \"note\": f\"Authority-like tokens detected ({', '.join(found_authorities)}) but questions_to_verify is empty\"\n","            })\n","\n","        # Risk: analysis sounds like conclusion (heuristic)\n","        analysis_text = result.get(\"analysis\", \"\").lower()\n","        conclusion_words = [\"therefore\", \"conclude\", \"must be\", \"is certain\", \"definitively\", \"proven\"]\n","        if any(word in analysis_text for word in conclusion_words):\n","            automated_risks.append({\n","                \"type\": \"overreach\",\n","                \"severity\": \"medium\",\n","                \"note\": \"Analysis contains conclusion-like language; ensure it's framed as reasoning structure only\"\n","            })\n","\n","        # Merge automated risks with model-provided risks\n","        existing_risks = result.get(\"risks\", [])\n","        all_risks = existing_risks + automated_risks\n","        result[\"risks\"] = all_risks\n","\n","        # Update risk_log.json\n","        risk_log_data = json.loads(risk_log_path.read_text())\n","        risk_log_data[\"entries\"].append({\n","            \"timestamp_utc\": now_iso(),\n","            \"task_name\": task_name,\n","            \"prompt_hash\": prompt_hash,\n","            \"response_hash\": response_hash,\n","            \"risks\": all_risks\n","        })\n","        write_json(risk_log_path, risk_log_data)\n","\n","        print(f\"âœ“ Reasoner call completed\")\n","        print(f\"  - Facts provided: {len(result.get('facts_provided', []))}\")\n","        print(f\"  - Assumptions: {len(result.get('assumptions', []))}\")\n","        print(f\"  - Open questions: {len(result.get('open_questions', []))}\")\n","        print(f\"  - Risks flagged: {len(all_risks)}\")\n","\n","        return result\n","\n","    except Exception as e:\n","        print(f\"âœ— Error calling reasoner: {e}\")\n","        import traceback\n","        print(f\"âœ— Traceback: {traceback.format_exc()}\")\n","        return None\n","\n","print(\"âœ“ Reasoner wrapper defined: call_reasoner()\")\n","print(\"âœ“ JSON cleaning utility: clean_json_response()\")\n","\n","# Smoke test\n","print(\"\\n\" + \"=\"*70)\n","print(\"SMOKE TEST: Reasoner Call\")\n","print(\"=\"*70)\n","\n","test_result = call_reasoner(\n","    task_name=\"Smoke Test\",\n","    user_prompt=\"Generate a simple example showing the JSON structure with at least 2 facts, 1 assumption, and 2 open questions.\",\n","    facts_bullets=\"â€¢ Test scenario for smoke test\\nâ€¢ No real data used\"\n",")\n","\n","if test_result:\n","    print(\"\\nâœ“ SMOKE TEST PASSED\")\n","    print(f\"  Task: {test_result.get('task')}\")\n","    print(f\"  Verification status: {test_result.get('verification_status')}\")\n","else:\n","    print(\"\\nâœ— SMOKE TEST FAILED - Check API key and model availability\")\n","\n","print(\"\\nReady to proceed to mini-case builders (Cell 7)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZALS-ZeQnh3p","executionInfo":{"status":"ok","timestamp":1768161171495,"user_tz":360,"elapsed":12052,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"00821739-1085-4949-eaca-2ee50f23fbc7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 6: LLM Wrapper for Level 2 Reasoned Structuring\n","======================================================================\n","âœ“ Reasoner wrapper defined: call_reasoner()\n","âœ“ JSON cleaning utility: clean_json_response()\n","\n","======================================================================\n","SMOKE TEST: Reasoner Call\n","======================================================================\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Calling reasoner: Smoke Test\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","âœ“ Reasoner call completed\n","  - Facts provided: 2\n","  - Assumptions: 1\n","  - Open questions: 2\n","  - Risks flagged: 2\n","\n","âœ“ SMOKE TEST PASSED\n","  Task: Smoke test to validate JSON structure and Level 2 reasoning boundaries\n","  Verification status: Not verified\n","\n","Ready to proceed to mini-case builders (Cell 7)\n"]}]},{"cell_type":"markdown","source":["##7.MINI CASE BUILDER"],"metadata":{"id":"Dr34h4v4M8SU"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"EnAuC2ckM_GU"}},{"cell_type":"markdown","source":["**Cell 7: Building the Mini-Cases â€“ Real-World Scenarios for Practice**\n","\n","**What This Cell Does:**\n","\n","This cell defines four realistic professional scenarios that demonstrate how Level 2 AI reasoning applies to different areas of accounting and audit practice. Rather than abstract examples, these mini-cases mirror situations you'll encounter in actual engagements: unusual financial statement variances, internal control weaknesses, complex tax positions, and training challenges. Each scenario is intentionally incompleteâ€”missing key facts that would be needed for final conclusionsâ€”to demonstrate how AI helps structure your thinking when information is imperfect.\n","\n","**Mini-Case 1: Financial Statement Audit (Revenue Variance):**\n","\n","You're reviewing a manufacturing client where Q4 revenue jumped 18 percent but gross margin dropped 6 percentage points. Management blames it on a new product line with lower margins, but you don't have detailed sales mix data yet. This case teaches you how to generate competing hypotheses (maybe it's the product mix, maybe it's pricing pressure, maybe there's a revenue recognition issue) and how to develop disconfirming-evidence questions that test each hypothesis. The key lesson: never accept the first explanation without considering alternatives.\n","\n","**Mini-Case 2: SOX/ICFR (IT-Dependent Manual Control):**\n","\n","A monthly inventory reconciliation control has multiple red flags: the person doing the reconciliation also has access to warehouse transactions (segregation of duties issue), one reconciliation was completed late, another showed an unexplained difference marked \"timing\" with no follow-up. This scenario demonstrates issue-spottingâ€”teaching you how to identify both design deficiencies (problems with how the control is set up) and operating effectiveness deficiencies (problems with how it's actually being performed).\n","\n","**Mini-Case 3: Tax/ASC 740 (Uncertain Tax Position):**\n","\n","A software company has an employee working remotely in State X, generating two million dollars in revenue from that state's customers, but management hasn't filed a state tax return because they claim no nexus exists. This case shows how to scaffold research questions without fabricating citations, how to identify what evidence you'd need from the client and tax advisor, and how to maintain \"Not verified\" discipline when discussing technical authorities.\n","\n","**Mini-Case 4: Teaching and Methodology:**\n","\n","Your firm wants to train 50 staff members on using AI responsibly. This meta-case demonstrates how to create training rubrics, design quizzes that test understanding of key concepts (facts versus assumptions, verification requirements), and identify risks in AI adoption like overconfidence or lack of skepticism."],"metadata":{"id":"EKvlFydjNrmX"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"X1KSLRldNBYW"}},{"cell_type":"code","source":["# Cell 7: Mini-Case Builders (4 Scenarios Aligned to Level 2)\n","\n","print(\"=\" * 70)\n","print(\"CELL 7: Mini-Case Scenario Definitions\")\n","print(\"=\" * 70)\n","\n","def minicase_fs_audit_variance():\n","    \"\"\"\n","    Mini-Case 1: FS Audit â€” Revenue variance hypotheses + disconfirming evidence\n","    \"\"\"\n","    task_name = \"FS_Audit_Revenue_Variance_Hypotheses\"\n","\n","    facts = \"\"\"â€¢ Client: Manufacturing company, calendar year-end 12/31/2024\n","- Q4 2024 revenue: $45M (PY Q4: $38M, +18.4% YoY)\n","- Gross margin Q4 2024: 22% (PY Q4: 28%, -600 bps)\n","- New product line launched Q3 2024 with lower margins\n","- Sales mix data: not yet available for Q4\n","- Management explanation: \"Volume growth drove revenue increase; new product has lower margin profile\"\n","- No unusual journal entries identified in preliminary analytics\n","- Accounts receivable days outstanding: 48 (PY: 42)\n","- Customer concentration: top 3 customers = 35% of revenue (PY: 28%)\"\"\"\n","\n","    user_prompt = \"\"\"Your task:\n","1. Generate variance hypotheses for BOTH revenue increase and gross margin decrease\n","2. For each hypothesis, list disconfirming-evidence questions (professional skepticism)\n","3. Draft a follow-up plan skeleton showing:\n","   - What procedures to consider (do NOT claim they were performed)\n","   - What evidence to request\n","   - What analytics to run\n","4. Flag any independence, confidentiality, or hallucination risks\n","5. Identify open questions that need management/auditor follow-up\n","\n","IMPORTANT: This is reasoning support only. Do not conclude the variance is or isn't a risk.\"\"\"\n","\n","    return task_name, facts, user_prompt\n","\n","\n","def minicase_sox_icfr_issue_spotting():\n","    \"\"\"\n","    Mini-Case 2: SOX/ICFR â€” Issue-spotting for IT-dependent manual control\n","    \"\"\"\n","    task_name = \"SOX_ICFR_Issue_Spotting_IT_Manual_Control\"\n","\n","    facts = \"\"\"â€¢ Control: Monthly reconciliation of inventory subledger to GL\n","- Control owner: Inventory Accountant (not segregated from warehouse transactions)\n","- Frequency: Monthly, by 5th business day\n","- IT system: Legacy ERP system with manual interfaces\n","- Control description: \"Compare inventory subledger report to GL balance; investigate differences >$10K\"\n","- Evidence: Reconciliation spreadsheet with sign-off\n","- Testing period: July-December 2024\n","- Observation: November reconciliation completed on 8th business day (late)\n","- Observation: October reconciliation showed $12K difference marked \"timing\" with no follow-up documentation\n","- IT general controls: Annual review, no deficiencies noted in 2023\n","- Automated controls: None for this process\"\"\"\n","\n","    user_prompt = \"\"\"Your task:\n","1. Issue-spot potential design and operating effectiveness deficiencies\n","2. For each issue, identify missing control objective clarity or design elements\n","3. Propose a test approach (draft only; do not claim tests were performed)\n","4. Flag any QC (quality control), missing facts, or overreach risks\n","5. Identify open questions for the internal audit team\n","\n","IMPORTANT: This is issue-spotting support only. Do not conclude the control is or isn't effective.\"\"\"\n","\n","    return task_name, facts, user_prompt\n","\n","\n","def minicase_tax_asc740_scaffold():\n","    \"\"\"\n","    Mini-Case 3: Tax/ASC 740 â€” Research scaffold without citations\n","    \"\"\"\n","    task_name = \"Tax_ASC740_Research_Scaffold_Uncertain_Position\"\n","\n","    facts = \"\"\"â€¢ Entity: US C-corp, software industry\n","- Issue: Tax treatment of R&D capitalization under updated IRS regulations (2024)\n","- Prior treatment: Expensed R&D costs immediately\n","- New requirement: Capitalize and amortize R&D over 5/15 years (domestic/foreign)\n","- Impact: Increase in taxable income; potential deferred tax asset\n","- Question: Recognition threshold for uncertain tax position related to nexus in State X\n","- State X nexus: Employee working remotely; no physical office; $2M revenue from State X customers\n","- Management position: No nexus; no state tax return filed\n","- Tax advisor: \"More likely than not\" threshold unclear for remote-employee nexus post-Wayfair\n","- No specific facts pattern on prior case law or IRS/state guidance\"\"\"\n","\n","    user_prompt = \"\"\"Your task:\n","1. Frame the ASC 740 research questions (do NOT provide ASC citations; use \"Not verified\" placeholders)\n","2. Identify evidence needs (what documents/data to request from client and tax advisor)\n","3. Draft a memo shell structure with \"Not verified\" warnings for any authority-like statements\n","4. Create a provision binder request list (what should be in the tax provision workpapers)\n","5. Flag hallucination risks if any authority-like language is used\n","6. Populate questions_to_verify with specific items to check in ASC/IRS guidance\n","\n","IMPORTANT: This is a research scaffold only. Do not conclude the position is or isn't supportable.\"\"\"\n","\n","    return task_name, facts, user_prompt\n","\n","\n","def minicase_teaching_methodology():\n","    \"\"\"\n","    Mini-Case 4: Teaching â€” Level 2 training rubric + quiz\n","    \"\"\"\n","    task_name = \"Teaching_Level2_Training_Rubric_Quiz\"\n","\n","    facts = \"\"\"â€¢ Training context: CPA firm, 50-person firm, mix of seniors and managers\n","- Goal: Train staff on Level 2 AI reasoners (structured reasoning support)\n","- Current state: Staff have used ChatGPT for research; no formal AI training\n","- Concerns: Over-reliance on AI; lack of professional skepticism; not verifying AI output\n","- Desired outcome: Staff understand facts vs assumptions, \"Not verified\" discipline, open questions requirement\n","- Training format: 2-hour workshop + take-home exercises\"\"\"\n","\n","    user_prompt = \"\"\"Your task:\n","1. Create a training rubric for evaluating Level 2 AI outputs, including:\n","   - Facts vs assumptions policing checklist\n","   - \"Not verified\" discipline for authority-like statements\n","   - Open questions requirement (skepticism)\n","   - QC (quality control) sign-off process\n","2. Draft a short quiz (5 questions) testing these concepts\n","   - Include 2 scenario-based questions with \"good\" vs \"bad\" AI output examples\n","   - Quiz should be validated by instructor later (flag as draft)\n","3. Identify risks in AI training (e.g., over-confidence, prompt injection, confidentiality)\n","4. List open questions for workshop design\n","\n","IMPORTANT: This is training material draft only. Instructor review required before use.\"\"\"\n","\n","    return task_name, facts, user_prompt\n","\n","\n","# Register all mini-cases\n","MINI_CASES = [\n","    minicase_fs_audit_variance,\n","    minicase_sox_icfr_issue_spotting,\n","    minicase_tax_asc740_scaffold,\n","    minicase_teaching_methodology\n","]\n","\n","print(f\"âœ“ {len(MINI_CASES)} mini-case builders loaded:\")\n","for i, case_func in enumerate(MINI_CASES, 1):\n","    task_name, _, _ = case_func()\n","    print(f\"  {i}. {task_name}\")\n","\n","print(\"\\nReady to proceed to running mini-cases (Cell 8)\")"],"metadata":{"id":"vw3KXun5NDTt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768161180250,"user_tz":360,"elapsed":18,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c39a33bf-f881-4b54-a558-c02fcb24c1ee"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 7: Mini-Case Scenario Definitions\n","======================================================================\n","âœ“ 4 mini-case builders loaded:\n","  1. FS_Audit_Revenue_Variance_Hypotheses\n","  2. SOX_ICFR_Issue_Spotting_IT_Manual_Control\n","  3. Tax_ASC740_Research_Scaffold_Uncertain_Position\n","  4. Teaching_Level2_Training_Rubric_Quiz\n","\n","Ready to proceed to running mini-cases (Cell 8)\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"E9DiNZg2NOyv"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"Ee1sdukLNP3S"}},{"cell_type":"markdown","source":["**Cell 8: Running the Demonstrations â€“ Seeing Level 2 Reasoning in Action**\n","\n","**What This Cell Does:**\n","\n","This is where theory becomes practice. Cell 8 takes the four mini-cases you just learned about and actually runs them through Claude, generating complete outputs for each scenario. You'll see the AI in action, structuring reasoning, flagging risks, and producing draft deliverablesâ€”all while the governance systems capture everything in your audit trail. This cell demonstrates the full workflow from raw facts to documented output, showing you what professional-grade AI assistance looks like.\n","\n","**The Processing Loop:**\n","\n","The cell processes each mini-case sequentially, and you can watch the progress in real-time. For each scenario, it first applies the redaction utilities from Cell 5 to ensure any sensitive information is masked. Then it calls the reasoner wrapper from Cell 6, which sends the scenario to Claude with strict instructions. The AI responds with structured JSON containing facts, assumptions, open questions, analysis, risks, and a draft deliverable. This entire interactionâ€”prompt, response, and metadataâ€”gets logged to your prompts_log.jsonl file with cryptographic hashes.\n","\n","**Two Output Formats for Different Purposes:**\n","\n","Each mini-case generates two files in your deliverables folder. The JSON file preserves the raw structured dataâ€”perfect for programmatic analysis or quality control software. The TXT file transforms that data into a human-readable report with clear sections, disclaimer language, and formatting that makes it easy for a reviewing CPA to evaluate. Both files serve the same content but optimize for different audiences: machines versus humans.\n","\n","**The Results Summary Table:**\n","\n","After processing all four cases, the cell displays a plain-text table summarizing key quality metrics. You'll see how many open questions each case generated (more is betterâ€”it shows professional skepticism), what the highest risk severity was (high-severity risks demand immediate attention), and whether any overreach was detected (cases where Claude might have stepped beyond reasoning support into conclusion territory). This table gives supervisors a quick way to triage which outputs need the most careful review.\n","\n","**The Minimum Standard Document:**\n","\n","Finally, the cell creates a reference document called level2_minimum_standard.txt that codifies the seven quality requirements every Level 2 output must meet. This becomes your checklist for evaluating not just these four demos but any future AI-assisted work you do."],"metadata":{"id":"UPGXnne7NtGW"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"BIE5Ni_wNRvq"}},{"cell_type":"code","source":["# Cell 8: Run 4 Mini-Case Demos + Save Deliverables\n","\n","print(\"=\" * 70)\n","print(\"CELL 8: Running Mini-Case Demonstrations\")\n","print(\"=\" * 70)\n","\n","results_summary = []\n","\n","for i, case_func in enumerate(MINI_CASES, 1):\n","    print(f\"\\n{'='*70}\")\n","    print(f\"MINI-CASE {i}/{len(MINI_CASES)}\")\n","    print(f\"{'='*70}\")\n","\n","    task_name, facts_text, user_prompt = case_func()\n","\n","    # Build minimum-necessary facts (redacted)\n","    facts_bullets, removed_summary = build_minimum_necessary(facts_text)\n","    print(f\"Facts prepared (removed: {removed_summary})\")\n","\n","    # Call reasoner\n","    result = call_reasoner(task_name, user_prompt, facts_bullets)\n","\n","    if result:\n","        # Save JSON deliverable\n","        json_path = DELIVERABLES_DIR / f\"{task_name}_output.json\"\n","        write_json(json_path, result)\n","        print(f\"\\nâœ“ JSON saved: {json_path}\")\n","\n","        # Create human-readable draft\n","        draft_lines = [\n","            \"=\"*70,\n","            f\"TASK: {task_name}\",\n","            \"=\"*70,\n","            \"\",\n","            \"ðŸš¨ NOT ACCOUNTING/AUDIT/TAX ADVICE ðŸš¨\",\n","            \"CPA review and engagement sign-off required.\",\n","            \"\",\n","            \"FACTS PROVIDED:\",\n","            *[f\"  {fact}\" for fact in result.get('facts_provided', [])],\n","            \"\",\n","            \"ASSUMPTIONS (MUST BE VALIDATED):\",\n","            *[f\"  {assumption}\" for assumption in result.get('assumptions', [])],\n","            \"\",\n","            \"OPEN QUESTIONS:\",\n","            *[f\"  {q}\" for q in result.get('open_questions', [])],\n","            \"\",\n","            \"ANALYSIS (reasoning structure notes):\",\n","            textwrap.fill(result.get('analysis', ''), width=70),\n","            \"\",\n","            \"RISKS FLAGGED:\",\n","            *[f\"  - [{r['severity'].upper()}] {r['type']}: {r['note']}\" for r in result.get('risks', [])],\n","            \"\",\n","            f\"VERIFICATION STATUS: {result.get('verification_status')}\",\n","            \"\",\n","            \"QUESTIONS TO VERIFY:\",\n","            *[f\"  {q}\" for q in result.get('questions_to_verify', [])],\n","            \"\",\n","            \"-\"*70,\n","            \"DRAFT OUTPUT:\",\n","            \"-\"*70,\n","            result.get('draft_output', ''),\n","            \"\"\n","        ]\n","\n","        draft_text = '\\n'.join(draft_lines)\n","        draft_path = DELIVERABLES_DIR / f\"{task_name}_draft.txt\"\n","        draft_path.write_text(draft_text, encoding='utf-8')\n","        print(f\"âœ“ Draft saved: {draft_path}\")\n","\n","        # Collect summary\n","        risks = result.get('risks', [])\n","        highest_risk = 'none'\n","        if risks:\n","            severity_order = {'high': 3, 'medium': 2, 'low': 1}\n","            highest_risk = max(risks, key=lambda r: severity_order.get(r['severity'], 0))['severity']\n","\n","        overreach_flagged = any(r['type'] == 'overreach' for r in risks)\n","\n","        results_summary.append({\n","            'case': task_name,\n","            'open_questions': len(result.get('open_questions', [])),\n","            'highest_risk': highest_risk,\n","            'overreach_flagged': 'Yes' if overreach_flagged else 'No'\n","        })\n","    else:\n","        print(f\"\\nâœ— Failed to process {task_name}\")\n","        results_summary.append({\n","            'case': task_name,\n","            'open_questions': 0,\n","            'highest_risk': 'ERROR',\n","            'overreach_flagged': 'N/A'\n","        })\n","\n","# Create Level 2 minimum standard document\n","standard_text = \"\"\"Level 2 Reasoners: Minimum Quality Standard\n","==============================================\n","\n","Level 2 AI reasoners provide structured reasoning support for accounting and audit professionals.\n","To ensure safe and effective use, every Level 2 output must meet these minimum standards:\n","\n","1. FACTS VS ASSUMPTIONS DISCIPLINE\n","   âœ“ Explicitly separate what was stated (facts_provided) from what was inferred (assumptions)\n","   âœ“ All assumptions must be validated by human professionals\n","   âœ“ Never claim procedures were performed unless stated in facts\n","\n","2. \"NOT VERIFIED\" GATE\n","   âœ“ Any reference to ASC, PCAOB, AICPA, SEC, GAAS, or other authorities must be flagged \"Not verified\"\n","   âœ“ Populate questions_to_verify with specific items to check in authoritative literature\n","   âœ“ Never fabricate citations or requirements\n","\n","3. PROFESSIONAL SKEPTICISM (DISCONFIRMING EVIDENCE)\n","   âœ“ Every hypothesis must include disconfirming-evidence questions\n","   âœ“ Open questions are REQUIRED to identify missing facts\n","   âœ“ Challenge assumptions and look for alternative explanations\n","\n","4. LEVEL 2 BOUNDARY ENFORCEMENT\n","   âœ“ Reasoning support ONLY; no autonomous execution\n","   âœ“ No final conclusions or opinions\n","   âœ“ No procedures performed or evidence verified\n","   âœ“ Explicitly state: \"NOT ADVICE; CPA review required\"\n","\n","5. RISK FLAGGING\n","   âœ“ Identify confidentiality, independence, hallucination, missing facts, QC, overreach risks\n","   âœ“ Document risks in structured format with severity levels\n","   âœ“ Update risk log for auditability\n","\n","6. HUMAN REVIEW AND SIGN-OFF\n","   âœ“ All outputs are drafts requiring CPA review\n","   âœ“ Engagement sign-off required before use in real engagements\n","   âœ“ Maintain audit trail (run manifest, prompts log, risk log)\n","\n","7. REPRODUCIBILITY\n","   âœ“ Config hash + environment fingerprint for every run\n","   âœ“ Cryptographic hashes for prompts and responses\n","   âœ“ Zip bundle with complete audit trail\n","\n","Remember: Capability â†‘ â‡’ Risk â†‘ â‡’ Controls â†‘\n","\n","This is not a substitute for professional judgment. AI is a tool to structure thinking, not replace thinking.\n","\"\"\"\n","\n","standard_path = DELIVERABLES_DIR / \"level2_minimum_standard.txt\"\n","standard_path.write_text(standard_text, encoding='utf-8')\n","print(f\"\\nâœ“ Level 2 minimum standard saved: {standard_path}\")\n","\n","# Print summary table\n","print(\"\\n\" + \"=\"*70)\n","print(\"MINI-CASE RESULTS SUMMARY\")\n","print(\"=\"*70)\n","print(f\"{'Case':<45} {'Open Q':<8} {'Risk':<8} {'Overreach'}\")\n","print(\"-\"*70)\n","for row in results_summary:\n","    print(f\"{row['case']:<45} {row['open_questions']:<8} {row['highest_risk']:<8} {row['overreach_flagged']}\")\n","print(\"=\"*70)\n","\n","print(\"\\nReady to proceed to user exercise (Cell 9)\")"],"metadata":{"id":"GF7UbU5xNTWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768161561223,"user_tz":360,"elapsed":18608,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"66483415-4406-4de3-ef00-258a99c523d8"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 8: Running Mini-Case Demonstrations\n","======================================================================\n","\n","======================================================================\n","MINI-CASE 1/4\n","======================================================================\n","Facts prepared (removed: none)\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Calling reasoner: FS_Audit_Revenue_Variance_Hypotheses\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","âœ“ Reasoner call completed\n","  - Facts provided: 9\n","  - Assumptions: 8\n","  - Open questions: 15\n","  - Risks flagged: 5\n","\n","âœ“ JSON saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/FS_Audit_Revenue_Variance_Hypotheses_output.json\n","âœ“ Draft saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/FS_Audit_Revenue_Variance_Hypotheses_draft.txt\n","\n","======================================================================\n","MINI-CASE 2/4\n","======================================================================\n","Facts prepared (removed: possible_names_detected_not_redacted)\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Calling reasoner: SOX_ICFR_Issue_Spotting_IT_Manual_Control\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","âœ“ Reasoner call completed\n","  - Facts provided: 11\n","  - Assumptions: 8\n","  - Open questions: 16\n","  - Risks flagged: 6\n","\n","âœ“ JSON saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/SOX_ICFR_Issue_Spotting_IT_Manual_Control_output.json\n","âœ“ Draft saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/SOX_ICFR_Issue_Spotting_IT_Manual_Control_draft.txt\n","\n","======================================================================\n","MINI-CASE 3/4\n","======================================================================\n","Facts prepared (removed: none)\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Calling reasoner: Tax_ASC740_Research_Scaffold_Uncertain_Position\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","âœ“ Reasoner call completed\n","  - Facts provided: 8\n","  - Assumptions: 8\n","  - Open questions: 12\n","  - Risks flagged: 6\n","\n","âœ“ JSON saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/Tax_ASC740_Research_Scaffold_Uncertain_Position_output.json\n","âœ“ Draft saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/Tax_ASC740_Research_Scaffold_Uncertain_Position_draft.txt\n","\n","======================================================================\n","MINI-CASE 4/4\n","======================================================================\n","Facts prepared (removed: none)\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Calling reasoner: Teaching_Level2_Training_Rubric_Quiz\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","âœ“ Reasoner call completed\n","  - Facts provided: 6\n","  - Assumptions: 7\n","  - Open questions: 12\n","  - Risks flagged: 7\n","\n","âœ“ JSON saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/Teaching_Level2_Training_Rubric_Quiz_output.json\n","âœ“ Draft saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/Teaching_Level2_Training_Rubric_Quiz_draft.txt\n","\n","âœ“ Level 2 minimum standard saved: /content/ai_audit_ch2_runs/run_20260111_192247/deliverables/level2_minimum_standard.txt\n","\n","======================================================================\n","MINI-CASE RESULTS SUMMARY\n","======================================================================\n","Case                                          Open Q   Risk     Overreach\n","----------------------------------------------------------------------\n","FS_Audit_Revenue_Variance_Hypotheses          15       high     Yes\n","SOX_ICFR_Issue_Spotting_IT_Manual_Control     16       high     Yes\n","Tax_ASC740_Research_Scaffold_Uncertain_Position 12       high     Yes\n","Teaching_Level2_Training_Rubric_Quiz          12       high     Yes\n","======================================================================\n","\n","Ready to proceed to user exercise (Cell 9)\n"]}]},{"cell_type":"markdown","source":["##9.USER EXERCISE"],"metadata":{"id":"3juVsof2NUJC"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"0A7X8eAeNVjp"}},{"cell_type":"markdown","source":["**Cell 9: Your Turn â€“ Applying AI Reasoning to Your Own Scenario**\n","\n","**What This Cell Does:**\n","\n","After observing four demonstration cases, now you get hands-on experience. Cell 9 transforms the notebook from a passive learning tool into an interactive workspace where you can input your own scenario and receive structured reasoning support. This is where the training becomes practicalâ€”you'll see how the same governance controls, redaction utilities, and quality checks apply to scenarios you create, not just pre-built examples.\n","\n","**The Three-Step Safe Intake Process:**\n","\n","The cell guides you through a carefully designed input process. Step one asks you to type or paste your scenario, with prominent reminders to use only synthetic or heavily redacted data. The interface accepts multi-line input, so you can provide as much context as needed. Step two automatically runs the redaction function and shows you what was removedâ€”emails, phone numbers, addresses, or other PII. You'll see both the cleaned version and a summary of removed fields. Step three asks for explicit confirmation before proceeding, giving you a chance to review and cancel if anything looks problematic.\n","\n","**Choosing Your Exercise Type:**\n","\n","Not all professional scenarios require the same kind of reasoning support. The cell offers three distinct exercise types aligned to common CPA workflows. **Variance hypotheses** helps you analyze unexpected changes in financial statement line itemsâ€”perfect for audit analytics or monthly financial reviews. **Issue spotting** guides you through identifying control deficiencies in SOX compliance or internal audit contexts. **ASC scaffold** structures your approach to complex accounting research questions, especially useful for technical accounting memos or tax provision work.\n","\n","**Real-Time Output Generation:**\n","\n","Once you select your exercise type, the cell calls the same reasoner wrapper used in the demos, applying identical quality controls and documentation standards. Within seconds, you'll receive structured output showing what facts Claude extracted from your scenario, what assumptions it made that you need to validate, what questions remain unanswered, and what risks exist in the analysis. This isn't a generic responseâ€”it's tailored specifically to your input and your chosen exercise type.\n","\n","**Your Personal Deliverables:**\n","\n","The cell saves two files with your results: user_exercise_output.json for the structured data and user_exercise_output.txt for the readable report. These files join the demo outputs in your deliverables folder, creating a complete portfolio of both training examples and your own work."],"metadata":{"id":"7SgqchOZNupJ"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"q65FZs56NXZp"}},{"cell_type":"code","source":["# Cell 9: User Exercise â€” Your Turn (Safe Intake + Reasoned Scaffold)\n","\n","print(\"=\" * 70)\n","print(\"CELL 9: User Exercise â€” Your Own Scenario\")\n","print(\"=\" * 70)\n","\n","print(\"\"\"\n","This cell lets you input your own scenario and get Level 2 reasoning support.\n","\n","âš  CRITICAL REMINDERS:\n","1. Use REDACTED or SYNTHETIC data only (no real client information)\n","2. Even with redaction, be cautious about what you input\n","3. All outputs are DRAFTS requiring CPA review\n","\"\"\")\n","\n","# Get user scenario\n","print(\"\\nStep 1: Enter your scenario (use synthetic/redacted data)\")\n","print(\"Press Enter twice when done:\\n\")\n","\n","user_lines = []\n","while True:\n","    line = input()\n","    if line == \"\" and len(user_lines) > 0 and user_lines[-1] == \"\":\n","        break\n","    user_lines.append(line)\n","\n","user_scenario = '\\n'.join(user_lines).strip()\n","\n","if not user_scenario:\n","    print(\"\\nâš  No scenario entered. Skipping user exercise.\")\n","else:\n","    # Redact the scenario\n","    print(\"\\nStep 2: Applying redaction...\")\n","    redacted_scenario, removed_fields = redact(user_scenario)\n","\n","    print(\"\\nREDACTION SUMMARY:\")\n","    print(f\"  Removed fields: {', '.join(removed_fields) if removed_fields else 'none'}\")\n","\n","    if removed_fields:\n","        print(\"\\nâš  PII detected and redacted. Review output carefully.\")\n","        print(\"\\nREDACTED SCENARIO:\")\n","        print(redacted_scenario)\n","        confirm = input(\"\\nContinue with this redacted scenario? (yes/no): \").strip().lower()\n","        if confirm != 'yes':\n","            print(\"User exercise cancelled.\")\n","            redacted_scenario = None\n","\n","    if redacted_scenario:\n","        # Build sanitized facts\n","        facts_bullets, _ = build_minimum_necessary(redacted_scenario)\n","\n","        # Get exercise type\n","        print(\"\\nStep 3: Select exercise type\")\n","        print(\"  1. variance_hypotheses (revenue/expense variance analysis)\")\n","        print(\"  2. issue_spotting (internal control deficiencies)\")\n","        print(\"  3. asc_scaffold (tax/accounting research framework)\")\n","\n","        exercise_choice = input(\"\\nEnter 1, 2, or 3: \").strip()\n","\n","        exercise_map = {\n","            '1': ('variance_hypotheses', \"\"\"Generate variance hypotheses and disconfirming-evidence questions for the scenario.\n","Include: hypotheses list, skepticism questions, follow-up plan skeleton, risk flags.\"\"\"),\n","            '2': ('issue_spotting', \"\"\"Identify potential control design or operating effectiveness issues.\n","Include: issue list, missing control elements, proposed test approach (draft), risk flags.\"\"\"),\n","            '3': ('asc_scaffold', \"\"\"Create an accounting research scaffold with \"Not verified\" placeholders.\n","Include: research questions, evidence needs, memo shell, questions_to_verify.\"\"\")\n","        }\n","\n","        if exercise_choice in exercise_map:\n","            exercise_type, exercise_prompt = exercise_map[exercise_choice]\n","            task_name = f\"User_Exercise_{exercise_type}\"\n","\n","            print(f\"\\nRunning exercise: {exercise_type}\")\n","\n","            # Call reasoner\n","            result = call_reasoner(task_name, exercise_prompt, facts_bullets)\n","\n","            if result:\n","                # Save JSON\n","                json_path = DELIVERABLES_DIR / \"user_exercise_output.json\"\n","                write_json(json_path, result)\n","                print(f\"\\nâœ“ JSON saved: {json_path}\")\n","\n","                # Save readable output\n","                output_lines = [\n","                    \"=\"*70,\n","                    \"USER EXERCISE OUTPUT\",\n","                    \"=\"*70,\n","                    \"\",\n","                    \"ðŸš¨ NOT ACCOUNTING/AUDIT/TAX ADVICE ðŸš¨\",\n","                    \"This is a DRAFT requiring CPA review.\",\n","                    \"\",\n","                    f\"Exercise type: {exercise_type}\",\n","                    \"\",\n","                    \"YOUR SANITIZED FACTS:\",\n","                    facts_bullets,\n","                    \"\",\n","                    \"ASSUMPTIONS (MUST BE VALIDATED):\",\n","                    *[f\"  {a}\" for a in result.get('assumptions', [])],\n","                    \"\",\n","                    \"OPEN QUESTIONS:\",\n","                    *[f\"  {q}\" for q in result.get('open_questions', [])],\n","                    \"\",\n","                    \"ANALYSIS:\",\n","                    textwrap.fill(result.get('analysis', ''), width=70),\n","                    \"\",\n","                    \"RISKS:\",\n","                    *[f\"  - [{r['severity'].upper()}] {r['type']}: {r['note']}\" for r in result.get('risks', [])],\n","                    \"\",\n","                    f\"VERIFICATION STATUS: {result.get('verification_status')}\",\n","                    \"\",\n","                    \"QUESTIONS TO VERIFY:\",\n","                    *[f\"  {q}\" for q in result.get('questions_to_verify', [])],\n","                    \"\",\n","                    \"-\"*70,\n","                    \"DRAFT OUTPUT:\",\n","                    \"-\"*70,\n","                    result.get('draft_output', ''),\n","                    \"\"\n","                ]\n","\n","                output_text = '\\n'.join(output_lines)\n","                txt_path = DELIVERABLES_DIR / \"user_exercise_output.txt\"\n","                txt_path.write_text(output_text, encoding='utf-8')\n","                print(f\"âœ“ Readable output saved: {txt_path}\")\n","\n","                print(\"\\n\" + \"=\"*70)\n","                print(\"USER EXERCISE COMPLETE\")\n","                print(\"=\"*70)\n","                print(f\"Redaction applied: {len(removed_fields) > 0}\")\n","                print(f\"Open questions: {len(result.get('open_questions', []))}\")\n","                print(f\"Risks flagged: {len(result.get('risks', []))}\")\n","                print(\"\\nâš  Remember: Review output carefully and obtain CPA sign-off before use.\")\n","            else:\n","                print(\"\\nâœ— Exercise failed\")\n","        else:\n","            print(\"\\nâš  Invalid exercise type selected.\")\n","\n","print(\"\\nReady to proceed to final bundling (Cell 10)\")"],"metadata":{"id":"h8-UJrsrNZmu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##10.AUDIT ARTIFACTS"],"metadata":{"id":"deALRI7DNc11"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"hspK-tF8Nd9D"}},{"cell_type":"markdown","source":["**Cell 10: Bundling Your Audit Trail â€“ Creating Complete Documentation**\n","\n","**What This Cell Does:**\n","\n","This final cell packages everything you've created during this session into a professional, downloadable audit trail. Think of it as closing out an engagement binderâ€”you're gathering all working papers, creating an index, and preparing documentation that could be reviewed by a partner, regulator, or quality control team months or years from now. This isn't an afterthought; it's a demonstration that AI-assisted work can meet the same documentation standards as traditional professional services.\n","\n","**The Audit README â€“ Your Documentation Guide:**\n","\n","The cell generates a comprehensive AUDIT_README.txt file that serves as the cover memo for your entire bundle. This document explains what each artifact is, why it exists, and how to use it. For someone unfamiliar with this notebook, the README provides step-by-step instructions: verify reproducibility by checking the config hash, review the redacted prompts carefully for any residual sensitive content, examine the risk register for flagged issues, validate that all deliverables include proper disclaimers, and obtain CPA sign-off before using anything in real engagements.\n","\n","**Understanding the File Inventory:**\n","\n","Before creating the zip file, the cell walks through your run directory and lists every single file that will be included. You'll see the manifest, the prompt log, the risk log, the README, and all deliverables from both the demos and your user exercise. This transparency is intentionalâ€”you should know exactly what's being bundled. The cell counts the files and displays their relative paths, giving you confidence that nothing is missing and nothing unexpected is included.\n","\n","**The ZIP Bundle â€“ Portable and Archivable:**\n","\n","The cell uses Python's built-in compression tools to create a single ZIP file containing your entire run directory. The filename includes your unique run ID (timestamp plus config hash prefix), making it easy to distinguish this session from others if you run the notebook multiple times. The cell displays the ZIP file's size and location, and since it's saved in the /content/ directory, you can download it directly from Colab's file browser.\n","\n","**The Final Checklist â€“ Quality Assurance:**\n","\n","Before declaring success, the cell runs through a six-item checklist verifying that all critical artifacts exist: manifest, prompt log, risk log, README, deliverables folder, and ZIP bundle. Each item shows a checkmark or X, giving you visual confirmation that your audit trail is complete and ready for review."],"metadata":{"id":"QktoO36gNwPN"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-qPlPvQYNhIv"}},{"cell_type":"code","source":["# Cell 10: Bundle Artifacts + Audit Readme + Zip\n","\n","print(\"=\" * 70)\n","print(\"CELL 10: Final Artifact Bundling and Audit Trail\")\n","print(\"=\" * 70)\n","\n","# Create AUDIT_README.txt\n","readme_text = f\"\"\"AUDIT TRAIL README\n","==================\n","\n","Run ID: {RUN_ID}\n","Generated: {now_iso()}\n","Chapter: 2 (Level 2 Reasoners)\n","Model: {MODEL}\n","\n","ARTIFACTS IN THIS BUNDLE\n","------------------------\n","\n","1. run_manifest.json\n","   - Run ID, timestamp, model configuration\n","   - Config hash for reproducibility\n","   - Environment fingerprint (Python version, system info, library versions)\n","   - Full base configuration with control list\n","\n","2. prompts_log.jsonl\n","   - JSONL format (one JSON object per line)\n","   - Redacted prompts and responses (PII removed via heuristics)\n","   - Cryptographic hashes (SHA256) for each prompt/response\n","   - Model name and temperature for each call\n","   - âš  CAUTION: Even though redacted, review carefully before sharing\n","\n","3. risk_log.json\n","   - Risk register with entries for each deliverable\n","   - Risk types: confidentiality, independence, hallucination, missing_facts, qc, overreach, etc.\n","   - Severity levels (low/medium/high)\n","   - Linked to prompts via hashes for traceability\n","\n","4. deliverables/ folder\n","   - Structured JSON outputs for each mini-case + user exercise\n","   - Human-readable .txt drafts with disclaimers\n","   - level2_minimum_standard.txt (quality standard checklist)\n","\n","HOW TO REVIEW THIS AUDIT TRAIL\n","-------------------------------\n","\n","STEP 1: Verify Reproducibility\n","- Check run_manifest.json for model, temperature, max_tokens\n","- Note config_hash; identical config = identical setup\n","- Compare environment fingerprint if reproducing in different environment\n","\n","STEP 2: Review Prompts (with Caution)\n","- Open prompts_log.jsonl in a text editor\n","- Each line is a separate JSON object\n","- Prompts are redacted but may still contain sensitive context\n","- Use prompt_hash and response_hash to link to risk_log entries\n","\n","STEP 3: Check Risk Register\n","- Open risk_log.json\n","- Review all flagged risks (especially \"high\" severity)\n","- Verify \"Not verified\" discipline was enforced\n","- Confirm overreach risks were caught\n","\n","STEP 4: Validate Deliverables\n","- Review each *_output.json for strict schema compliance\n","- Check *_draft.txt files for:\n","  * Disclaimer present (\"NOT ADVICE\")\n","  * Facts vs assumptions separated\n","  * Open questions listed\n","  * Verification status = \"Not verified\" where appropriate\n","- Ensure no fabricated citations (check questions_to_verify)\n","\n","STEP 5: CPA Review and Sign-Off\n","- All outputs are DRAFTS\n","- Engagement partner or manager must review\n","- Document review in engagement files\n","- Obtain sign-off before using in real engagements\n","\n","LEVEL 2 BOUNDARY REMINDER\n","--------------------------\n","\n","Level 2 reasoners provide STRUCTURED REASONING SUPPORT ONLY:\n","âœ“ Hypotheses, issue lists, research scaffolds\n","âœ“ Disconfirming-evidence questions (skepticism)\n","âœ“ Draft frameworks and checklists\n","\n","Level 2 does NOT:\n","âœ— Perform procedures or verify evidence\n","âœ— Provide final conclusions or opinions\n","âœ— Act as autonomous agents\n","âœ— Replace professional judgment\n","\n","Remember: Capability â†‘ â‡’ Risk â†‘ â‡’ Controls â†‘\n","\n","CONFIDENTIALITY WARNING\n","-----------------------\n","\n","Even with redaction utilities:\n","- Do NOT share this bundle externally without scrubbing\n","- Review prompts_log.jsonl carefully (may contain context clues)\n","- Remove any client-specific information before archiving\n","- Follow your firm's data retention and disposal policies\n","\n","SUPPORT\n","-------\n","\n","For questions about this audit trail or Level 2 reasoners:\n","- Review level2_minimum_standard.txt in deliverables/\n","- Consult your firm's AI governance policies\n","- Contact: Alejandro Reynoso, Chief Scientist DEFI CAPITAL RESEARCH\n","\n","This README is part of a research and training initiative.\n","Not for distribution without permission.\n","\"\"\"\n","\n","readme_path = RUN_DIR / \"AUDIT_README.txt\"\n","readme_path.write_text(readme_text, encoding='utf-8')\n","print(f\"âœ“ AUDIT_README.txt created: {readme_path}\")\n","\n","# List all files in run directory\n","print(\"\\n\" + \"=\"*70)\n","print(\"FILES IN AUDIT TRAIL\")\n","print(\"=\"*70)\n","\n","all_files = []\n","for item in RUN_DIR.rglob('*'):\n","    if item.is_file():\n","        rel_path = item.relative_to(RUN_DIR)\n","        all_files.append(str(rel_path))\n","        print(f\"  {rel_path}\")\n","\n","print(f\"\\nTotal files: {len(all_files)}\")\n","\n","# Create zip bundle\n","zip_filename = f\"ai_audit_ch2_{RUN_ID}.zip\"\n","zip_path = RUN_BASE_DIR / zip_filename\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"CREATING ZIP BUNDLE\")\n","print(\"=\"*70)\n","\n","import shutil\n","shutil.make_archive(\n","    str(RUN_BASE_DIR / f\"ai_audit_ch2_{RUN_ID}\"),\n","    'zip',\n","    RUN_DIR\n",")\n","\n","print(f\"âœ“ Zip bundle created: {zip_path}\")\n","print(f\"  Size: {zip_path.stat().st_size / 1024:.1f} KB\")\n","\n","# Final checklist\n","print(\"\\n\" + \"=\"*70)\n","print(\"FINAL CHECKLIST\")\n","print(\"=\"*70)\n","\n","checklist = [\n","    (\"run_manifest.json\", (RUN_DIR / \"run_manifest.json\").exists()),\n","    (\"prompts_log.jsonl\", (RUN_DIR / \"prompts_log.jsonl\").exists()),\n","    (\"risk_log.json\", (RUN_DIR / \"risk_log.json\").exists()),\n","    (\"AUDIT_README.txt\", readme_path.exists()),\n","    (\"deliverables/ folder\", DELIVERABLES_DIR.exists()),\n","    (\"Zip bundle\", zip_path.exists())\n","]\n","\n","for item, exists in checklist:\n","    status = \"âœ“\" if exists else \"âœ—\"\n","    print(f\"  {status} {item}\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"CHAPTER 2 NOTEBOOK COMPLETE\")\n","print(\"=\"*70)\n","\n","print(f\"\"\"\n","âœ“ All governance artifacts generated\n","âœ“ 4 mini-case demos completed\n","âœ“ User exercise ready\n","âœ“ Audit trail bundled\n","\n","NEXT STEPS:\n","1. Download zip: {zip_path}\n","2. Review AUDIT_README.txt for detailed instructions\n","3. Examine deliverables/ folder for outputs\n","4. Obtain CPA review and sign-off before using outputs\n","\n","Remember:\n","- These are DRAFTS, not final deliverables\n","- Facts â‰  Assumptions (validate all assumptions)\n","- \"Not verified\" discipline for authority-like statements\n","- Professional skepticism (disconfirming evidence)\n","- Engagement sign-off required\n","\n","Thank you for using Level 2 Reasoners responsibly.\n","\"\"\")\n","\n","print(\"\\nðŸŽ“ TRAINING COMPLETE: You now understand Level 2 reasoning support for accounting & audit.\")\n","print(\"ðŸ“¦ Download your audit trail and share with your team (after scrubbing sensitive data).\")"],"metadata":{"id":"STPTAD0YNi9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768161624219,"user_tz":360,"elapsed":29,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"5a7455ec-1873-45f5-a203-384b29e551d4"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CELL 10: Final Artifact Bundling and Audit Trail\n","======================================================================\n","âœ“ AUDIT_README.txt created: /content/ai_audit_ch2_runs/run_20260111_192247/AUDIT_README.txt\n","\n","======================================================================\n","FILES IN AUDIT TRAIL\n","======================================================================\n","  AUDIT_README.txt\n","  prompts_log.jsonl\n","  run_manifest.json\n","  risk_log.json\n","  deliverables/Tax_ASC740_Research_Scaffold_Uncertain_Position_output.json\n","  deliverables/level2_minimum_standard.txt\n","  deliverables/Tax_ASC740_Research_Scaffold_Uncertain_Position_draft.txt\n","  deliverables/SOX_ICFR_Issue_Spotting_IT_Manual_Control_draft.txt\n","  deliverables/Teaching_Level2_Training_Rubric_Quiz_draft.txt\n","  deliverables/FS_Audit_Revenue_Variance_Hypotheses_output.json\n","  deliverables/SOX_ICFR_Issue_Spotting_IT_Manual_Control_output.json\n","  deliverables/Teaching_Level2_Training_Rubric_Quiz_output.json\n","  deliverables/FS_Audit_Revenue_Variance_Hypotheses_draft.txt\n","\n","Total files: 13\n","\n","======================================================================\n","CREATING ZIP BUNDLE\n","======================================================================\n","âœ“ Zip bundle created: /content/ai_audit_ch2_runs/ai_audit_ch2_20260111_192247_22c12306caf0.zip\n","  Size: 59.4 KB\n","\n","======================================================================\n","FINAL CHECKLIST\n","======================================================================\n","  âœ“ run_manifest.json\n","  âœ“ prompts_log.jsonl\n","  âœ“ risk_log.json\n","  âœ“ AUDIT_README.txt\n","  âœ“ deliverables/ folder\n","  âœ“ Zip bundle\n","\n","======================================================================\n","CHAPTER 2 NOTEBOOK COMPLETE\n","======================================================================\n","\n","âœ“ All governance artifacts generated\n","âœ“ 4 mini-case demos completed\n","âœ“ User exercise ready\n","âœ“ Audit trail bundled\n","\n","NEXT STEPS:\n","1. Download zip: /content/ai_audit_ch2_runs/ai_audit_ch2_20260111_192247_22c12306caf0.zip\n","2. Review AUDIT_README.txt for detailed instructions\n","3. Examine deliverables/ folder for outputs\n","4. Obtain CPA review and sign-off before using outputs\n","\n","Remember:\n","- These are DRAFTS, not final deliverables\n","- Facts â‰  Assumptions (validate all assumptions)\n","- \"Not verified\" discipline for authority-like statements\n","- Professional skepticism (disconfirming evidence)\n","- Engagement sign-off required\n","\n","Thank you for using Level 2 Reasoners responsibly.\n","\n","\n","ðŸŽ“ TRAINING COMPLETE: You now understand Level 2 reasoning support for accounting & audit.\n","ðŸ“¦ Download your audit trail and share with your team (after scrubbing sensitive data).\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"7X2_AKt3NkAR"}},{"cell_type":"markdown","source":["**Conclusion: From Casual Chat to Professional-Grade AI Assistance**\n","\n","**The Complete Pipeline: Ten Steps to Trustworthy AI**\n","\n","This notebook has walked you through a deliberate, methodical transformation of AI interaction from casual conversation to professionally defensible work product. The pipeline we've constructed represents a fundamental reimagining of how accounting and audit professionals should engage with generative AI systems.\n","\n","The journey began with orientation and boundary-setting in Cell 1, establishing the core principle that Level 2 reasoners provide structured thinking support without crossing into autonomous decision-making or procedure execution. This wasn't mere disclaimer languageâ€”it defined the architectural constraints that every subsequent component respects. We then moved through technical foundation-building in Cells 2-3, where API connections and model parameters were explicitly configured and documented. The choice of low temperature (0.2) and the specification of model version weren't arbitrary technical details; they were governance decisions about consistency and reproducibility that get captured in the configuration hash.\n","\n","Cells 4-5 constructed the governance infrastructure that operates invisibly but critically throughout every interaction. The utility functions for timestamping, hashing, logging, and redaction created a safety net that catches potential issues before they become problems. The environment fingerprint captured in Cell 4 ensures that someone reviewing this work months later can understand the exact technical context in which it was produced. The redaction utilities in Cell 5 acknowledged a hard truth: even well-intentioned professionals make mistakes with confidential data, and automated safeguards provide essential protection.\n","\n","Cell 6 represented the intellectual heart of the systemâ€”the reasoner wrapper that transforms Claude from a general-purpose chatbot into a disciplined professional assistant. The strict JSON schema enforcement, the facts-versus-assumptions parsing, the automated risk flagging, and the \"Not verified\" discipline all converged in this single interface. Every subsequent AI interaction flowed through this wrapper, ensuring consistent application of governance controls regardless of who uses the notebook or what scenario they're analyzing.\n","\n","The mini-cases in Cells 7-8 demonstrated the system under realistic professional conditionsâ€”revenue variance analysis, internal control assessment, uncertain tax position research, and training methodology development. These weren't sanitized textbook examples but authentic scenarios with incomplete information, ambiguous facts, and multiple defensible interpretations. Watching the system process these cases revealed how governance mechanisms operate under pressure: facts were explicitly separated from assumptions, open questions were generated systematically, authority references were flagged for verification, and risk registers captured concerns in structured format rather than vague unease.\n","\n","Cell 9 transformed passive observation into active learning by letting you input your own scenario and experience the governed reasoning process firsthand. This hands-on component is crucial because understanding governance controls intellectually differs profoundly from experiencing them in practice. When you see your own scenario parsed into facts versus assumptions, when you receive disconfirming evidence questions that challenge your initial framing, when you get a risk register highlighting issues you hadn't consciously identifiedâ€”that's when the value proposition becomes tangible rather than theoretical.\n","\n","Finally, Cell 10 closed the loop by packaging the complete audit trail into a downloadable, reviewable, reproducible artifact bundle. The run manifest, prompts log, risk register, deliverables folder, and comprehensive README together constitute proof that professional standards were followed. This isn't bureaucratic overheadâ€”it's the evidence base that makes AI-assisted work defensible in quality control reviews, regulatory examinations, or litigation contexts.\n","\n","**The Pipeline's Core Innovation: Governance as Architecture, Not Afterthought**\n","\n","What distinguishes this notebook from typical AI tutorials is the recognition that governance cannot be bolted onto AI systems after the fact. The confidentiality protections, verification discipline, audit trail generation, and risk flagging weren't added as optional enhancementsâ€”they were embedded into the core architecture from the first line of code. You cannot use this system without generating an audit trail. You cannot get AI output without explicit facts-versus-assumptions parsing. You cannot reference authorities without \"Not verified\" flags. The system makes ungoverned AI use harder than governed use, which inverts the usual dynamic where shortcuts are easier than best practices.\n","\n","This architectural approach to governance has profound implications for professional services firms implementing AI. The usual pathâ€”deploy consumer chatbots, hope people use them responsibly, write policy documents nobody reads, deal with quality control failures reactivelyâ€”is exactly backward. The correct sequence is: define governance requirements first, engineer systems that enforce those requirements by design, then deploy tools that make compliant usage the path of least resistance.\n","\n","**The Essential Lesson: Control Enables Capability**\n","\n","The fundamental insight this notebook should impart transcends the specific technical implementation or the particular governance mechanisms we've constructed. The essential lesson is this: rigorous controls don't constrain AI capabilityâ€”they enable it. Without the governance infrastructure we've built, you cannot safely use AI for professional accounting and audit work, regardless of how impressive the underlying language model might be. With this infrastructure in place, AI becomes a legitimate tool for structuring professional judgment, generating hypotheses, identifying knowledge gaps, and documenting reasoning processes.\n","\n","The casual AI user asks: \"What's the answer to my question?\" The professional AI user asks: \"What facts have I provided? What assumptions am I making? What questions remain open? What risks exist in this analysis? How can I verify the output? How would I defend this work to a reviewer?\" This notebook has shown you how to operationalize that professional mindset through deliberate system design. The controls we've implementedâ€”facts versus assumptions, \"Not verified\" discipline, audit trails, risk registers, reproducibility mechanismsâ€”aren't obstacles between you and AI productivity. They're the foundation that makes professional AI use possible at all.\n","\n","As AI capabilities continue advancing at breakneck pace, the temptation will be to focus on what the newest models can do and to treat governance as a secondary concern that slows down innovation. Resist that temptation. The most important AI skill for professional services isn't prompt engineering or keeping up with model releasesâ€”it's the discipline to demand that powerful tools respect professional standards, maintain audit trails, acknowledge limitations explicitly, and support rather than replace human judgment. That discipline, more than any technical capability, will determine whether AI becomes a genuine asset to professional practice or a liability that undermines the credibility of the work we sign."],"metadata":{"id":"aV65a4QjNzQV"}},{"cell_type":"code","source":[],"metadata":{"id":"3BdM6IPANlZ-"},"execution_count":null,"outputs":[]}]}